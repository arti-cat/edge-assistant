# Python Vulnerability Scanner

Automated security vulnerability scanning for Python projects using advanced static analysis, dynamic testing, and CI/CD integration

## Instructions

Follow this comprehensive approach to implement automated security vulnerability scanning: **$ARGUMENTS**

1. **Environment and Project Analysis**
   - Analyze Python project structure and identify frameworks (Django, Flask, FastAPI, etc.)
   - Assess application type (web app, API, CLI tool, microservice, package)
   - Review existing security tooling and CI/CD pipeline configuration
   - Identify critical security domains (authentication, data handling, API endpoints)
   - Map attack surfaces and high-risk code paths

2. **Security Tool Installation and Configuration**
   ```bash
   # Install comprehensive security scanning tools
   uv add --dev semgrep bandit safety pip-audit
   uv add --dev detect-secrets truffleHog
   uv add --dev vulncost dockerfile-audit
   uv add --dev checkov trivy

   # Install advanced SAST tools
   uv add --dev codeql-cli sonarqube-scanner
   uv add --dev bearer-cli horusec

   # Install dynamic analysis tools
   uv add --dev zap-cli sslyze
   uv add --dev pytest-security pytest-html
   ```

3. **Advanced Static Analysis Configuration**
   ```toml
   # pyproject.toml - Security scanning configuration
   [tool.uv.scripts]
   scan-security = "python scripts/security_scanner.py"
   scan-static = "semgrep --config=auto --config=security-audit --sarif -o static-analysis.sarif src/"
   scan-bandit = "bandit -r src/ -f sarif -o bandit-results.sarif"
   scan-secrets = "detect-secrets scan --all-files --force-use-all-plugins"
   scan-dependencies = "pip-audit --format=sarif --output=dependency-audit.sarif"
   scan-container = "trivy fs --format sarif --output trivy-results.sarif ."
   scan-infrastructure = "checkov -d . --framework dockerfile --framework kubernetes --output sarif"
   scan-comprehensive = ["scan-static", "scan-bandit", "scan-secrets", "scan-dependencies"]

   [tool.bandit]
   exclude_dirs = ["tests", "migrations", "venv", ".venv"]
   skips = ["B101"]  # Skip assert_used in tests

   [tool.bandit.assert_used]
   exclude = ["*_test.py", "**/test_*.py"]

   [tool.semgrep]
   config = [
       "auto",
       "security-audit",
       "owasp-top-10",
       "cwe-top-25",
       "python-security"
   ]
   exclude = ["tests/", "migrations/", "*.pyc"]

   [tool.detect-secrets]
   exclude_files = "poetry.lock|\\.secrets\\.baseline$|test_.*\\.py$"
   plugins_used = [
       "ArtifactoryDetector",
       "AWSKeyDetector",
       "Base64HighEntropyString",
       "BasicAuthDetector",
       "CloudantDetector",
       "IbmCloudIamDetector",
       "IbmCosHmacDetector",
       "JwtTokenDetector",
       "KeywordDetector",
       "MailchimpDetector",
       "PrivateKeyDetector",
       "SlackDetector",
       "SoftlayerDetector",
       "SquareOAuthDetector",
       "StripeDetector",
       "TwilioKeyDetector"
   ]
   ```

4. **Comprehensive Security Scanner Implementation**
   ```python
   # scripts/security_scanner.py
   import asyncio
   import json
   import subprocess
   import sys
   from datetime import datetime, timezone
   from pathlib import Path
   from typing import Dict, List, Optional, Tuple
   import logging
   from dataclasses import dataclass, asdict
   from enum import Enum

   class SeverityLevel(Enum):
       CRITICAL = "critical"
       HIGH = "high"
       MEDIUM = "medium"
       LOW = "low"
       INFO = "info"

   @dataclass
   class SecurityFinding:
       id: str
       title: str
       description: str
       severity: SeverityLevel
       confidence: str
       file_path: str
       line_number: Optional[int]
       tool: str
       rule_id: str
       cwe_id: Optional[str]
       remediation: str
       evidence: Optional[str]

   class PythonVulnerabilityScanner:
       def __init__(self, project_root: Path):
           self.project_root = project_root
           self.findings: List[SecurityFinding] = []
           self.setup_logging()

       def setup_logging(self):
           """Configure security scanning logging"""
           logging.basicConfig(
               level=logging.INFO,
               format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
               handlers=[
                   logging.FileHandler('security-scan.log'),
                   logging.StreamHandler(sys.stdout)
               ]
           )
           self.logger = logging.getLogger('security_scanner')

       async def run_comprehensive_scan(self) -> Dict:
           """Execute all security scanning tools"""
           self.logger.info("Starting comprehensive security vulnerability scan")

           scan_tasks = [
               self.run_semgrep_scan(),
               self.run_bandit_scan(),
               self.run_safety_scan(),
               self.run_pip_audit_scan(),
               self.run_secrets_scan(),
               self.run_dependency_analysis(),
               self.run_container_scan(),
               self.run_infrastructure_scan(),
               self.run_custom_python_checks()
           ]

           results = await asyncio.gather(*scan_tasks, return_exceptions=True)

           # Process and aggregate results
           report = self.generate_security_report()
           self.export_sarif_report()

           return report

       async def run_semgrep_scan(self) -> List[SecurityFinding]:
           """Run Semgrep static analysis with security rules"""
           self.logger.info("Running Semgrep security analysis")

           cmd = [
               "semgrep",
               "--config=auto",
               "--config=security-audit",
               "--config=owasp-top-10",
               "--config=cwe-top-25",
               "--json",
               str(self.project_root / "src")
           ]

           try:
               result = subprocess.run(cmd, capture_output=True, text=True, check=True)
               semgrep_results = json.loads(result.stdout)

               findings = []
               for finding in semgrep_results.get('results', []):
                   security_finding = SecurityFinding(
                       id=f"semgrep-{finding['check_id']}",
                       title=finding['message'],
                       description=finding.get('metadata', {}).get('summary', ''),
                       severity=self._map_severity(finding.get('metadata', {}).get('severity', 'medium')),
                       confidence=finding.get('metadata', {}).get('confidence', 'medium'),
                       file_path=finding['path'],
                       line_number=finding['start']['line'],
                       tool='semgrep',
                       rule_id=finding['check_id'],
                       cwe_id=finding.get('metadata', {}).get('cwe'),
                       remediation=finding.get('metadata', {}).get('fix', 'Review and fix identified security issue'),
                       evidence=finding.get('extra', {}).get('lines')
                   )
                   findings.append(security_finding)

               self.findings.extend(findings)
               return findings

           except subprocess.CalledProcessError as e:
               self.logger.error(f"Semgrep scan failed: {e}")
               return []

       async def run_bandit_scan(self) -> List[SecurityFinding]:
           """Run Bandit security linter"""
           self.logger.info("Running Bandit security analysis")

           cmd = ["bandit", "-r", "src/", "-f", "json"]

           try:
               result = subprocess.run(cmd, capture_output=True, text=True)
               bandit_results = json.loads(result.stdout)

               findings = []
               for issue in bandit_results.get('results', []):
                   security_finding = SecurityFinding(
                       id=f"bandit-{issue['test_id']}",
                       title=issue['test_name'],
                       description=issue['issue_text'],
                       severity=self._map_severity(issue['issue_severity']),
                       confidence=issue['issue_confidence'].lower(),
                       file_path=issue['filename'],
                       line_number=issue['line_number'],
                       tool='bandit',
                       rule_id=issue['test_id'],
                       cwe_id=issue.get('cwe_id'),
                       remediation=issue.get('more_info', 'Review Bandit documentation'),
                       evidence=issue.get('code', '')
                   )
                   findings.append(security_finding)

               self.findings.extend(findings)
               return findings

           except (subprocess.CalledProcessError, json.JSONDecodeError) as e:
               self.logger.error(f"Bandit scan failed: {e}")
               return []

       async def run_safety_scan(self) -> List[SecurityFinding]:
           """Run Safety dependency vulnerability check"""
           self.logger.info("Running Safety dependency scan")

           cmd = ["safety", "check", "--json"]

           try:
               result = subprocess.run(cmd, capture_output=True, text=True)
               safety_results = json.loads(result.stdout)

               findings = []
               for vuln in safety_results:
                   security_finding = SecurityFinding(
                       id=f"safety-{vuln['id']}",
                       title=f"Vulnerable dependency: {vuln['package_name']}",
                       description=vuln['advisory'],
                       severity=self._map_cve_severity(vuln.get('cve')),
                       confidence='high',
                       file_path='requirements.txt',
                       line_number=None,
                       tool='safety',
                       rule_id=vuln['id'],
                       cwe_id=None,
                       remediation=f"Update {vuln['package_name']} to version {vuln.get('safe_version', 'latest')}",
                       evidence=f"Vulnerable version: {vuln['installed_version']}"
                   )
                   findings.append(security_finding)

               self.findings.extend(findings)
               return findings

           except (subprocess.CalledProcessError, json.JSONDecodeError) as e:
               self.logger.warning(f"Safety scan completed with issues: {e}")
               return []

       async def run_pip_audit_scan(self) -> List[SecurityFinding]:
           """Run pip-audit for comprehensive dependency scanning"""
           self.logger.info("Running pip-audit dependency scan")

           cmd = ["pip-audit", "--format=json"]

           try:
               result = subprocess.run(cmd, capture_output=True, text=True, check=True)
               audit_results = json.loads(result.stdout)

               findings = []
               for vuln in audit_results.get('vulnerabilities', []):
                   security_finding = SecurityFinding(
                       id=f"pip-audit-{vuln['id']}",
                       title=f"Dependency vulnerability in {vuln['package']}",
                       description=vuln['description'],
                       severity=self._map_severity(vuln.get('severity', 'medium')),
                       confidence='high',
                       file_path='pyproject.toml',
                       line_number=None,
                       tool='pip-audit',
                       rule_id=vuln['id'],
                       cwe_id=None,
                       remediation=f"Update {vuln['package']} from {vuln['installed_version']} to {vuln.get('fixed_version', 'latest')}",
                       evidence=f"Affected versions: {vuln.get('affected_versions', 'N/A')}"
                   )
                   findings.append(security_finding)

               self.findings.extend(findings)
               return findings

           except subprocess.CalledProcessError as e:
               self.logger.warning(f"pip-audit scan completed: {e}")
               return []

       async def run_secrets_scan(self) -> List[SecurityFinding]:
           """Run detect-secrets for hardcoded secrets detection"""
           self.logger.info("Running secrets detection scan")

           cmd = ["detect-secrets", "scan", "--all-files", "--force-use-all-plugins"]

           try:
               result = subprocess.run(cmd, capture_output=True, text=True, check=True)
               secrets_results = json.loads(result.stdout)

               findings = []
               for file_path, secrets in secrets_results.get('results', {}).items():
                   for secret in secrets:
                       security_finding = SecurityFinding(
                           id=f"secrets-{secret['hashed_secret'][:8]}",
                           title=f"Potential secret detected: {secret['type']}",
                           description=f"Hardcoded secret detected in source code",
                           severity=SeverityLevel.HIGH,
                           confidence='medium',
                           file_path=file_path,
                           line_number=secret['line_number'],
                           tool='detect-secrets',
                           rule_id=secret['type'],
                           cwe_id='CWE-798',
                           remediation="Remove hardcoded secret and use environment variables or secret management service",
                           evidence=f"Secret type: {secret['type']}"
                       )
                       findings.append(security_finding)

               self.findings.extend(findings)
               return findings

           except subprocess.CalledProcessError as e:
               self.logger.info(f"Secrets scan completed: {e}")
               return []

       async def run_dependency_analysis(self) -> List[SecurityFinding]:
           """Analyze dependency security and licensing"""
           self.logger.info("Running dependency security analysis")

           # Check for known vulnerable packages
           vulnerable_packages = {
               'django': ['<3.2.0', 'Known XSS vulnerabilities'],
               'flask': ['<2.0.0', 'Security header issues'],
               'requests': ['<2.25.0', 'TLS verification bypass'],
               'pyyaml': ['<5.4.0', 'Arbitrary code execution'],
               'jinja2': ['<2.11.3', 'XSS vulnerabilities'],
               'pillow': ['<8.1.1', 'Buffer overflow vulnerabilities']
           }

           findings = []

           # Parse pyproject.toml or requirements.txt
           try:
               import tomli
               with open(self.project_root / 'pyproject.toml', 'rb') as f:
                   pyproject = tomli.load(f)
                   dependencies = pyproject.get('project', {}).get('dependencies', [])

               for dep in dependencies:
                   pkg_name = dep.split('[')[0].split('=')[0].split('>')[0].split('<')[0].strip()
                   if pkg_name in vulnerable_packages:
                       version_constraint, description = vulnerable_packages[pkg_name]
                       security_finding = SecurityFinding(
                           id=f"dep-analysis-{pkg_name}",
                           title=f"Potentially vulnerable dependency: {pkg_name}",
                           description=description,
                           severity=SeverityLevel.MEDIUM,
                           confidence='medium',
                           file_path='pyproject.toml',
                           line_number=None,
                           tool='dependency-analysis',
                           rule_id=f"vuln-{pkg_name}",
                           cwe_id=None,
                           remediation=f"Update {pkg_name} to latest secure version",
                           evidence=f"Current constraint: {dep}"
                       )
                       findings.append(security_finding)

           except Exception as e:
               self.logger.warning(f"Could not parse dependencies: {e}")

           self.findings.extend(findings)
           return findings

       async def run_container_scan(self) -> List[SecurityFinding]:
           """Scan container configurations for security issues"""
           self.logger.info("Running container security scan")

           findings = []

           # Check for Dockerfile security issues
           dockerfile_path = self.project_root / 'Dockerfile'
           if dockerfile_path.exists():
               cmd = ["trivy", "config", "--format", "json", str(dockerfile_path)]

               try:
                   result = subprocess.run(cmd, capture_output=True, text=True, check=True)
                   trivy_results = json.loads(result.stdout)

                   for result in trivy_results.get('Results', []):
                       for misconfig in result.get('Misconfigurations', []):
                           security_finding = SecurityFinding(
                               id=f"container-{misconfig['ID']}",
                               title=misconfig['Title'],
                               description=misconfig['Description'],
                               severity=self._map_severity(misconfig['Severity']),
                               confidence='high',
                               file_path='Dockerfile',
                               line_number=misconfig.get('CauseMetadata', {}).get('StartLine'),
                               tool='trivy',
                               rule_id=misconfig['ID'],
                               cwe_id=None,
                               remediation=misconfig.get('Resolution', 'Fix container configuration'),
                               evidence=misconfig.get('Message', '')
                           )
                           findings.append(security_finding)

               except subprocess.CalledProcessError as e:
                   self.logger.warning(f"Container scan failed: {e}")

           self.findings.extend(findings)
           return findings

       async def run_infrastructure_scan(self) -> List[SecurityFinding]:
           """Scan infrastructure as code for security misconfigurations"""
           self.logger.info("Running infrastructure security scan")

           cmd = ["checkov", "-d", ".", "--framework", "dockerfile", "--framework", "kubernetes", "--output", "json"]

           try:
               result = subprocess.run(cmd, capture_output=True, text=True)
               checkov_results = json.loads(result.stdout)

               findings = []
               for check in checkov_results.get('results', {}).get('failed_checks', []):
                   security_finding = SecurityFinding(
                       id=f"infra-{check['check_id']}",
                       title=check['check_name'],
                       description=check['description'],
                       severity=SeverityLevel.MEDIUM,
                       confidence='high',
                       file_path=check['file_path'],
                       line_number=check.get('file_line_range', [None])[0],
                       tool='checkov',
                       rule_id=check['check_id'],
                       cwe_id=None,
                       remediation=check.get('guideline', 'Review infrastructure configuration'),
                       evidence=''
                   )
                   findings.append(security_finding)

               self.findings.extend(findings)
               return findings

           except (subprocess.CalledProcessError, json.JSONDecodeError) as e:
               self.logger.warning(f"Infrastructure scan completed: {e}")
               return []

       async def run_custom_python_checks(self) -> List[SecurityFinding]:
           """Run custom Python-specific security checks"""
           self.logger.info("Running custom Python security checks")

           findings = []

           # Check for dangerous Python patterns
           dangerous_patterns = {
               'eval(': 'Code injection vulnerability - avoid eval()',
               'exec(': 'Code injection vulnerability - avoid exec()',
               'input(': 'Potential input validation issue',
               'os.system(': 'Command injection vulnerability',
               'subprocess.call(': 'Potential command injection',
               'pickle.loads(': 'Deserialization vulnerability',
               'yaml.load(': 'YAML deserialization vulnerability - use safe_load()',
               'shell=True': 'Command injection risk with shell=True',
               'urllib.urlopen(': 'Use requests library instead',
               'random.random()': 'Use secrets module for cryptographic randomness'
           }

           for py_file in self.project_root.rglob('*.py'):
               if 'test' in str(py_file) or 'migration' in str(py_file):
                   continue

               try:
                   content = py_file.read_text()
                   lines = content.split('\n')

                   for line_num, line in enumerate(lines, 1):
                       for pattern, description in dangerous_patterns.items():
                           if pattern in line and not line.strip().startswith('#'):
                               security_finding = SecurityFinding(
                                   id=f"custom-{pattern.replace('(', '').replace(')', '')}-{py_file.name}-{line_num}",
                                   title=f"Dangerous pattern detected: {pattern}",
                                   description=description,
                                   severity=SeverityLevel.HIGH if 'injection' in description else SeverityLevel.MEDIUM,
                                   confidence='medium',
                                   file_path=str(py_file.relative_to(self.project_root)),
                                   line_number=line_num,
                                   tool='custom-checks',
                                   rule_id=f"dangerous-{pattern.replace('(', '').replace(')', '')}",
                                   cwe_id='CWE-94' if 'injection' in description else None,
                                   remediation=description,
                                   evidence=line.strip()
                               )
                               findings.append(security_finding)

               except Exception as e:
                   self.logger.warning(f"Could not scan {py_file}: {e}")

           self.findings.extend(findings)
           return findings

       def generate_security_report(self) -> Dict:
           """Generate comprehensive security report"""

           # Categorize findings by severity
           severity_counts = {level.value: 0 for level in SeverityLevel}
           tool_counts = {}

           for finding in self.findings:
               severity_counts[finding.severity.value] += 1
               tool_counts[finding.tool] = tool_counts.get(finding.tool, 0) + 1

           # Calculate risk score
           risk_score = (
               severity_counts['critical'] * 10 +
               severity_counts['high'] * 7 +
               severity_counts['medium'] * 4 +
               severity_counts['low'] * 1
           )

           report = {
               'scan_metadata': {
                   'timestamp': datetime.now(timezone.utc).isoformat(),
                   'project_root': str(self.project_root),
                   'total_findings': len(self.findings),
                   'risk_score': risk_score,
                   'risk_level': self._get_risk_level(risk_score)
               },
               'summary': {
                   'by_severity': severity_counts,
                   'by_tool': tool_counts
               },
               'findings': [asdict(finding) for finding in self.findings],
               'recommendations': self._generate_recommendations()
           }

           # Save report
           with open('security-report.json', 'w') as f:
               json.dump(report, f, indent=2, default=str)

           self.logger.info(f"Security scan completed. Found {len(self.findings)} issues. Risk score: {risk_score}")

           return report

       def export_sarif_report(self):
           """Export findings in SARIF format for security dashboards"""

           sarif_report = {
               "version": "2.1.0",
               "$schema": "https://json.schemastore.org/sarif-2.1.0.json",
               "runs": [{
                   "tool": {
                       "driver": {
                           "name": "Python Vulnerability Scanner",
                           "version": "1.0.0",
                           "informationUri": "https://github.com/your-org/python-vulnerability-scanner"
                       }
                   },
                   "results": []
               }]
           }

           for finding in self.findings:
               sarif_result = {
                   "ruleId": finding.rule_id,
                   "message": {"text": finding.description},
                   "level": finding.severity.value,
                   "locations": [{
                       "physicalLocation": {
                           "artifactLocation": {"uri": finding.file_path},
                           "region": {"startLine": finding.line_number or 1}
                       }
                   }],
                   "properties": {
                       "tool": finding.tool,
                       "confidence": finding.confidence,
                       "cwe": finding.cwe_id,
                       "remediation": finding.remediation
                   }
               }
               sarif_report["runs"][0]["results"].append(sarif_result)

           with open('security-results.sarif', 'w') as f:
               json.dump(sarif_report, f, indent=2)

       def _map_severity(self, severity: str) -> SeverityLevel:
           """Map tool-specific severity to standard levels"""
           severity_map = {
               'error': SeverityLevel.HIGH,
               'warning': SeverityLevel.MEDIUM,
               'note': SeverityLevel.LOW,
               'info': SeverityLevel.INFO,
               'critical': SeverityLevel.CRITICAL,
               'high': SeverityLevel.HIGH,
               'medium': SeverityLevel.MEDIUM,
               'low': SeverityLevel.LOW
           }
           return severity_map.get(severity.lower(), SeverityLevel.MEDIUM)

       def _map_cve_severity(self, cve: Optional[str]) -> SeverityLevel:
           """Map CVE severity to standard levels"""
           if not cve:
               return SeverityLevel.MEDIUM
           # This would typically query CVE database for actual severity
           return SeverityLevel.HIGH

       def _get_risk_level(self, risk_score: int) -> str:
           """Calculate overall risk level"""
           if risk_score >= 50:
               return "CRITICAL"
           elif risk_score >= 30:
               return "HIGH"
           elif risk_score >= 15:
               return "MEDIUM"
           else:
               return "LOW"

       def _generate_recommendations(self) -> List[str]:
           """Generate remediation recommendations"""
           recommendations = []

           severity_counts = {level.value: 0 for level in SeverityLevel}
           for finding in self.findings:
               severity_counts[finding.severity.value] += 1

           if severity_counts['critical'] > 0:
               recommendations.append("🚨 CRITICAL: Address all critical vulnerabilities immediately")

           if severity_counts['high'] > 5:
               recommendations.append("⚠️  Multiple high-severity issues detected - prioritize remediation")

           recommendations.extend([
               "🔄 Update all dependencies to latest secure versions",
               "🔐 Implement comprehensive input validation",
               "📋 Add security scanning to CI/CD pipeline",
               "🛡️ Configure security headers and HTTPS",
               "📊 Set up continuous security monitoring",
               "🧪 Add security-focused unit tests",
               "📚 Conduct security code review",
               "🎯 Implement least privilege access controls"
           ])

           return recommendations

   # CLI interface
   if __name__ == "__main__":
       import argparse

       parser = argparse.ArgumentParser(description="Python Vulnerability Scanner")
       parser.add_argument("--project-root", default=".", help="Project root directory")
       parser.add_argument("--output-format", choices=["json", "sarif", "html"], default="json")
       args = parser.parse_args()

       scanner = PythonVulnerabilityScanner(Path(args.project_root))
       report = asyncio.run(scanner.run_comprehensive_scan())

       print(f"Scan completed. Found {report['scan_metadata']['total_findings']} security issues.")
       print(f"Risk Level: {report['scan_metadata']['risk_level']}")
   ```

5. **CI/CD Pipeline Integration**
   ```yaml
   # .github/workflows/security-scan.yml
   name: Security Vulnerability Scanning

   on:
     push:
       branches: [ main, develop ]
     pull_request:
       branches: [ main ]
     schedule:
       - cron: '0 2 * * 1'  # Weekly scan on Mondays

   jobs:
     security-scan:
       runs-on: ubuntu-latest
       permissions:
         security-events: write
         contents: read

       steps:
         - name: Checkout code
           uses: actions/checkout@v4

         - name: Set up Python
           uses: actions/setup-python@v4
           with:
             python-version: '3.11'

         - name: Install uv
           run: |
             curl -LsSf https://astral.sh/uv/install.sh | sh
             echo "$HOME/.cargo/bin" >> $GITHUB_PATH

         - name: Install dependencies
           run: |
             uv sync --dev

         - name: Run comprehensive security scan
           run: |
             uv run python scripts/security_scanner.py

         - name: Upload SARIF results to GitHub
           uses: github/codeql-action/upload-sarif@v2
           if: always()
           with:
             sarif_file: security-results.sarif

         - name: Upload security reports
           uses: actions/upload-artifact@v3
           if: always()
           with:
             name: security-reports
             path: |
               security-report.json
               security-results.sarif
               *.sarif

         - name: Comment PR with security summary
           if: github.event_name == 'pull_request'
           uses: actions/github-script@v6
           with:
             script: |
               const fs = require('fs');
               try {
                 const report = JSON.parse(fs.readFileSync('security-report.json', 'utf8'));
                 const summary = `
                 ## 🛡️ Security Scan Results

                 **Risk Level:** ${report.scan_metadata.risk_level}
                 **Total Findings:** ${report.scan_metadata.total_findings}

                 ### By Severity:
                 - 🚨 Critical: ${report.summary.by_severity.critical}
                 - ⚠️ High: ${report.summary.by_severity.high}
                 - 📋 Medium: ${report.summary.by_severity.medium}
                 - ℹ️ Low: ${report.summary.by_severity.low}

                 ### Recommendations:
                 ${report.recommendations.slice(0, 5).map(r => `- ${r}`).join('\n')}

                 View detailed results in the Actions artifacts.
                 `;

                 github.rest.issues.createComment({
                   issue_number: context.issue.number,
                   owner: context.repo.owner,
                   repo: context.repo.repo,
                   body: summary
                 });
               } catch (error) {
                 console.log('Could not post security summary:', error);
               }

     dependency-scan:
       runs-on: ubuntu-latest
       steps:
         - uses: actions/checkout@v4
         - name: Run Trivy vulnerability scanner
           uses: aquasecurity/trivy-action@master
           with:
             scan-type: 'fs'
             scan-ref: '.'
             format: 'sarif'
             output: 'trivy-results.sarif'

         - name: Upload Trivy scan results
           uses: github/codeql-action/upload-sarif@v2
           with:
             sarif_file: 'trivy-results.sarif'
   ```

6. **Dynamic Security Testing Integration**
   ```python
   # tests/security/test_security_dynamic.py
   import pytest
   import requests
   from unittest.mock import patch
   import json
   from pathlib import Path

   class TestDynamicSecurity:
       """Dynamic security testing for web applications"""

       @pytest.fixture
       def app_url(self):
           """Application URL for testing"""
           return "http://localhost:8000"

       def test_sql_injection_protection(self, app_url):
           """Test SQL injection protection"""
           payloads = [
               "' OR '1'='1",
               "'; DROP TABLE users; --",
               "' UNION SELECT * FROM users --"
           ]

           for payload in payloads:
               response = requests.get(f"{app_url}/api/users", params={"id": payload})
               assert response.status_code != 200 or "error" in response.text.lower()

       def test_xss_protection(self, app_url):
           """Test XSS protection"""
           xss_payloads = [
               "<script>alert('xss')</script>",
               "javascript:alert('xss')",
               "<img src=x onerror=alert('xss')>"
           ]

           for payload in xss_payloads:
               response = requests.post(f"{app_url}/api/comments",
                                      json={"content": payload})
               # Should either reject or sanitize
               assert payload not in response.text

       def test_authentication_bypass(self, app_url):
           """Test authentication bypass attempts"""
           protected_endpoints = [
               "/admin",
               "/api/users/profile",
               "/dashboard"
           ]

           for endpoint in protected_endpoints:
               response = requests.get(f"{app_url}{endpoint}")
               assert response.status_code in [401, 403, 302]  # Unauthorized or redirect

       def test_csrf_protection(self, app_url):
           """Test CSRF protection"""
           # Attempt state-changing operation without CSRF token
           response = requests.post(f"{app_url}/api/users/delete",
                                  json={"user_id": 1})
           assert response.status_code in [403, 400]  # Should be blocked

       def test_rate_limiting(self, app_url):
           """Test rate limiting protection"""
           for i in range(100):  # Rapid requests
               response = requests.get(f"{app_url}/api/data")
               if response.status_code == 429:  # Rate limited
                   break
           else:
               pytest.fail("Rate limiting not implemented")

   # Security performance testing
   @pytest.mark.performance
   def test_security_performance():
       """Test security controls don't significantly impact performance"""
       import time

       start_time = time.time()
       # Simulate security-heavy operations
       end_time = time.time()

       assert (end_time - start_time) < 2.0  # Security overhead < 2 seconds
   ```

7. **Container Security Scanning**
   ```dockerfile
   # Multi-stage secure Dockerfile
   FROM python:3.11-slim as builder

   # Security: Create non-root user
   RUN groupadd -r appuser && useradd -r -g appuser appuser

   # Security: Update packages and remove cache
   RUN apt-get update && apt-get upgrade -y \
       && apt-get clean \
       && rm -rf /var/lib/apt/lists/*

   # Install uv
   COPY --from=ghcr.io/astral-sh/uv:latest /uv /bin/uv

   # Install dependencies
   WORKDIR /app
   COPY pyproject.toml uv.lock ./
   RUN uv sync --frozen --no-dev

   FROM python:3.11-slim as runtime

   # Security configurations
   RUN groupadd -r appuser && useradd -r -g appuser appuser \
       && apt-get update && apt-get upgrade -y \
       && apt-get clean \
       && rm -rf /var/lib/apt/lists/*

   # Copy application
   WORKDIR /app
   COPY --from=builder /app/.venv /app/.venv
   COPY --chown=appuser:appuser . .

   # Security: Use non-root user
   USER appuser

   # Security: Remove unnecessary privileges
   RUN chmod -R 755 /app

   EXPOSE 8000
   CMD ["/app/.venv/bin/python", "-m", "uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
   ```

8. **Security Dashboard Integration**
   ```python
   # scripts/security_dashboard.py
   import json
   from pathlib import Path
   from datetime import datetime
   import sqlite3
   from typing import Dict, List
   import plotly.graph_objects as go
   import plotly.express as px
   from plotly.subplots import make_subplots

   class SecurityDashboard:
       def __init__(self, db_path: str = "security_metrics.db"):
           self.db_path = db_path
           self.init_database()

       def init_database(self):
           """Initialize SQLite database for security metrics"""
           conn = sqlite3.connect(self.db_path)
           cursor = conn.cursor()

           cursor.execute("""
               CREATE TABLE IF NOT EXISTS security_scans (
                   id INTEGER PRIMARY KEY AUTOINCREMENT,
                   timestamp TEXT NOT NULL,
                   total_findings INTEGER,
                   critical_count INTEGER,
                   high_count INTEGER,
                   medium_count INTEGER,
                   low_count INTEGER,
                   risk_score INTEGER,
                   risk_level TEXT
               )
           """)

           cursor.execute("""
               CREATE TABLE IF NOT EXISTS vulnerability_trends (
                   id INTEGER PRIMARY KEY AUTOINCREMENT,
                   scan_id INTEGER,
                   vulnerability_type TEXT,
                   count INTEGER,
                   FOREIGN KEY (scan_id) REFERENCES security_scans (id)
               )
           """)

           conn.commit()
           conn.close()

       def import_scan_results(self, report_path: str):
           """Import security scan results into database"""
           with open(report_path, 'r') as f:
               report = json.load(f)

           conn = sqlite3.connect(self.db_path)
           cursor = conn.cursor()

           # Insert scan summary
           cursor.execute("""
               INSERT INTO security_scans
               (timestamp, total_findings, critical_count, high_count,
                medium_count, low_count, risk_score, risk_level)
               VALUES (?, ?, ?, ?, ?, ?, ?, ?)
           """, (
               report['scan_metadata']['timestamp'],
               report['scan_metadata']['total_findings'],
               report['summary']['by_severity']['critical'],
               report['summary']['by_severity']['high'],
               report['summary']['by_severity']['medium'],
               report['summary']['by_severity']['low'],
               report['scan_metadata']['risk_score'],
               report['scan_metadata']['risk_level']
           ))

           scan_id = cursor.lastrowid

           # Insert vulnerability trends
           for vuln_type, count in report['summary']['by_tool'].items():
               cursor.execute("""
                   INSERT INTO vulnerability_trends (scan_id, vulnerability_type, count)
                   VALUES (?, ?, ?)
               """, (scan_id, vuln_type, count))

           conn.commit()
           conn.close()

       def generate_dashboard(self) -> str:
           """Generate HTML security dashboard"""
           conn = sqlite3.connect(self.db_path)

           # Risk trend over time
           risk_data = conn.execute("""
               SELECT timestamp, risk_score, risk_level
               FROM security_scans
               ORDER BY timestamp DESC LIMIT 30
           """).fetchall()

           # Vulnerability distribution
           latest_scan = conn.execute("""
               SELECT critical_count, high_count, medium_count, low_count
               FROM security_scans
               ORDER BY timestamp DESC LIMIT 1
           """).fetchone()

           conn.close()

           # Create dashboard plots
           fig = make_subplots(
               rows=2, cols=2,
               subplot_titles=['Risk Score Trend', 'Vulnerability Distribution',
                             'Recent Findings', 'Tool Effectiveness'],
               specs=[[{"secondary_y": False}, {"type": "pie"}],
                      [{"colspan": 2}, None]],
           )

           # Risk trend plot
           if risk_data:
               timestamps = [row[0] for row in risk_data]
               risk_scores = [row[1] for row in risk_data]

               fig.add_trace(
                   go.Scatter(x=timestamps, y=risk_scores,
                            mode='lines+markers', name='Risk Score'),
                   row=1, col=1
               )

           # Vulnerability pie chart
           if latest_scan:
               labels = ['Critical', 'High', 'Medium', 'Low']
               values = list(latest_scan)

               fig.add_trace(
                   go.Pie(labels=labels, values=values, name="Vulnerabilities"),
                   row=1, col=2
               )

           fig.update_layout(
               title="Security Dashboard",
               height=800,
               showlegend=True
           )

           dashboard_html = fig.to_html(include_plotlyjs='cdn')

           # Save dashboard
           with open('security_dashboard.html', 'w') as f:
               f.write(dashboard_html)

           return dashboard_html
   ```

9. **Vulnerability Prioritization Engine**
   ```python
   # scripts/vulnerability_prioritizer.py
   from dataclasses import dataclass
   from typing import List, Dict
   from enum import Enum
   import json

   class ExploitabilityLevel(Enum):
       CRITICAL = 4  # Active exploits in the wild
       HIGH = 3      # Proof of concept available
       MEDIUM = 2    # Theoretical exploit possible
       LOW = 1       # Difficult to exploit

   @dataclass
   class VulnerabilityPriority:
       finding_id: str
       priority_score: float
       business_impact: str
       exploitability: ExploitabilityLevel
       remediation_effort: str
       recommended_timeline: str

   class VulnerabilityPrioritizer:
       def __init__(self, business_context: Dict):
           self.business_context = business_context

       def prioritize_vulnerabilities(self, findings: List[Dict]) -> List[VulnerabilityPriority]:
           """Prioritize vulnerabilities based on risk and business impact"""
           priorities = []

           for finding in findings:
               priority = self._calculate_priority(finding)
               priorities.append(priority)

           return sorted(priorities, key=lambda x: x.priority_score, reverse=True)

       def _calculate_priority(self, finding: Dict) -> VulnerabilityPriority:
           """Calculate priority score using CVSS-like methodology"""

           # Base score from severity
           severity_scores = {
               'critical': 10.0,
               'high': 7.5,
               'medium': 5.0,
               'low': 2.5,
               'info': 1.0
           }

           base_score = severity_scores.get(finding['severity'], 2.5)

           # Exploitability modifiers
           exploitability_modifiers = {
               'injection': 2.0,  # SQL, Command injection
               'authentication': 1.8,
               'authorization': 1.6,
               'crypto': 1.4,
               'xss': 1.3,
               'csrf': 1.2,
               'information_disclosure': 1.1
           }

           # Check for exploitability patterns
           exploitability_multiplier = 1.0
           for pattern, multiplier in exploitability_modifiers.items():
               if pattern in finding.get('description', '').lower():
                   exploitability_multiplier = max(exploitability_multiplier, multiplier)

           # Business context modifiers
           business_multiplier = 1.0
           if finding['file_path'] in self.business_context.get('critical_files', []):
               business_multiplier = 1.5
           elif 'api' in finding['file_path'] or 'auth' in finding['file_path']:
               business_multiplier = 1.3

           # Calculate final priority score
           priority_score = base_score * exploitability_multiplier * business_multiplier

           # Determine business impact
           if priority_score >= 9.0:
               business_impact = "CRITICAL - Immediate business risk"
               timeline = "Fix within 24 hours"
           elif priority_score >= 7.0:
               business_impact = "HIGH - Significant business risk"
               timeline = "Fix within 1 week"
           elif priority_score >= 4.0:
               business_impact = "MEDIUM - Moderate business risk"
               timeline = "Fix within 1 month"
           else:
               business_impact = "LOW - Minimal business risk"
               timeline = "Fix in next development cycle"

           # Estimate remediation effort
           effort_patterns = {
               'dependency': 'Low - Update dependency version',
               'configuration': 'Low - Configuration change',
               'input_validation': 'Medium - Add validation logic',
               'authentication': 'High - Redesign auth flow',
               'architecture': 'High - Architectural changes required'
           }

           remediation_effort = "Medium - Code changes required"
           for pattern, effort in effort_patterns.items():
               if pattern in finding.get('remediation', '').lower():
                   remediation_effort = effort
                   break

           return VulnerabilityPriority(
               finding_id=finding['id'],
               priority_score=priority_score,
               business_impact=business_impact,
               exploitability=self._determine_exploitability(finding),
               remediation_effort=remediation_effort,
               recommended_timeline=timeline
           )

       def _determine_exploitability(self, finding: Dict) -> ExploitabilityLevel:
           """Determine exploitability level"""
           high_exploit_patterns = ['injection', 'rce', 'authentication bypass']
           medium_exploit_patterns = ['xss', 'csrf', 'information disclosure']

           description = finding.get('description', '').lower()

           for pattern in high_exploit_patterns:
               if pattern in description:
                   return ExploitabilityLevel.HIGH

           for pattern in medium_exploit_patterns:
               if pattern in description:
                   return ExploitabilityLevel.MEDIUM

           return ExploitabilityLevel.LOW
   ```

10. **Remediation Automation**
    ```python
    # scripts/auto_remediation.py
    import subprocess
    import json
    from pathlib import Path
    from typing import List, Dict
    import re

    class AutoRemediation:
        def __init__(self, project_root: Path):
            self.project_root = project_root

        def auto_fix_findings(self, findings: List[Dict]) -> Dict[str, str]:
            """Automatically fix certain types of vulnerabilities"""
            fix_results = {}

            for finding in findings:
                if finding['severity'] in ['critical', 'high']:
                    result = self._attempt_auto_fix(finding)
                    if result:
                        fix_results[finding['id']] = result

            return fix_results

        def _attempt_auto_fix(self, finding: Dict) -> str:
            """Attempt to automatically fix a vulnerability"""

            # Dependency vulnerability fixes
            if finding['tool'] in ['safety', 'pip-audit']:
                return self._fix_dependency_vulnerability(finding)

            # Secret detection fixes
            elif finding['tool'] == 'detect-secrets':
                return self._fix_secret_exposure(finding)

            # Bandit security issues
            elif finding['tool'] == 'bandit':
                return self._fix_bandit_issue(finding)

            # Semgrep security patterns
            elif finding['tool'] == 'semgrep':
                return self._fix_semgrep_issue(finding)

            return None

        def _fix_dependency_vulnerability(self, finding: Dict) -> str:
            """Fix dependency vulnerabilities by updating versions"""
            try:
                if 'Update' in finding['remediation']:
                    # Extract package name and target version
                    package_pattern = r'Update (\w+) (?:from .+ )?to (.+)'
                    match = re.search(package_pattern, finding['remediation'])

                    if match:
                        package_name, target_version = match.groups()

                        # Update using uv
                        cmd = ['uv', 'add', f"{package_name}=={target_version.strip()}"]
                        result = subprocess.run(cmd, capture_output=True, text=True)

                        if result.returncode == 0:
                            return f"Successfully updated {package_name} to {target_version}"
                        else:
                            return f"Failed to update {package_name}: {result.stderr}"

            except Exception as e:
                return f"Auto-fix failed: {str(e)}"

            return None

        def _fix_secret_exposure(self, finding: Dict) -> str:
            """Fix hardcoded secrets by moving to environment variables"""
            try:
                file_path = Path(finding['file_path'])
                if not file_path.exists():
                    return "File not found"

                content = file_path.read_text()
                lines = content.split('\n')

                if finding['line_number'] and finding['line_number'] <= len(lines):
                    line_idx = finding['line_number'] - 1
                    original_line = lines[line_idx]

                    # Replace common secret patterns with environment variables
                    secret_patterns = {
                        r'api_key\s*=\s*["\']([^"\']+)["\']': 'api_key = os.environ.get("API_KEY")',
                        r'secret_key\s*=\s*["\']([^"\']+)["\']': 'secret_key = os.environ.get("SECRET_KEY")',
                        r'password\s*=\s*["\']([^"\']+)["\']': 'password = os.environ.get("PASSWORD")',
                        r'token\s*=\s*["\']([^"\']+)["\']': 'token = os.environ.get("TOKEN")'
                    }

                    for pattern, replacement in secret_patterns.items():
                        if re.search(pattern, original_line, re.IGNORECASE):
                            lines[line_idx] = re.sub(pattern, replacement, original_line, flags=re.IGNORECASE)

                            # Add import if not present
                            if 'import os' not in content:
                                lines.insert(0, 'import os')

                            file_path.write_text('\n'.join(lines))
                            return f"Replaced hardcoded secret with environment variable"

            except Exception as e:
                return f"Auto-fix failed: {str(e)}"

            return None
    ```

11. **Security Metrics and KPIs**
    ```python
    # scripts/security_metrics.py
    from dataclasses import dataclass
    from typing import Dict, List
    from datetime import datetime, timedelta
    import json

    @dataclass
    class SecurityMetrics:
        scan_date: datetime
        total_vulnerabilities: int
        critical_count: int
        high_count: int
        medium_count: int
        low_count: int
        mean_time_to_fix: float  # days
        security_debt_score: float
        coverage_percentage: float
        false_positive_rate: float

    class SecurityMetricsCalculator:
        def __init__(self):
            self.historical_data = []

        def calculate_security_kpis(self, scan_results: List[Dict]) -> Dict:
            """Calculate key security performance indicators"""

            if not scan_results:
                return {}

            latest_scan = scan_results[-1]

            # Vulnerability trend analysis
            vulnerability_trend = self._calculate_vulnerability_trend(scan_results)

            # Mean time to fix calculation
            mttr = self._calculate_mean_time_to_fix(scan_results)

            # Security debt calculation
            security_debt = self._calculate_security_debt(latest_scan)

            # Coverage metrics
            coverage = self._calculate_security_coverage(latest_scan)

            return {
                'vulnerability_trend': vulnerability_trend,
                'mean_time_to_resolution': mttr,
                'security_debt_score': security_debt,
                'security_coverage': coverage,
                'risk_velocity': self._calculate_risk_velocity(scan_results),
                'tool_effectiveness': self._calculate_tool_effectiveness(scan_results),
                'compliance_score': self._calculate_compliance_score(latest_scan)
            }

        def _calculate_vulnerability_trend(self, scans: List[Dict]) -> Dict:
            """Calculate vulnerability trend over time"""
            if len(scans) < 2:
                return {'trend': 'insufficient_data'}

            current = scans[-1]['scan_metadata']['total_findings']
            previous = scans[-2]['scan_metadata']['total_findings']

            change = current - previous
            percentage_change = (change / previous * 100) if previous > 0 else 0

            return {
                'current_count': current,
                'previous_count': previous,
                'change': change,
                'percentage_change': percentage_change,
                'trend': 'improving' if change < 0 else 'degrading' if change > 0 else 'stable'
            }

        def _calculate_security_debt(self, scan: Dict) -> float:
            """Calculate technical security debt score"""
            severity_weights = {
                'critical': 10,
                'high': 7,
                'medium': 4,
                'low': 1
            }

            debt_score = 0
            for severity, count in scan['summary']['by_severity'].items():
                debt_score += count * severity_weights.get(severity, 1)

            return debt_score
    ```

This comprehensive Python vulnerability scanner command provides:

1. **Advanced Static Analysis**: Uses multiple tools (Semgrep, Bandit, pip-audit) with custom Python security checks
2. **Dynamic Security Testing**: Includes runtime security testing capabilities
3. **Container & Infrastructure Scanning**: Scans Docker and Kubernetes configurations
4. **CI/CD Integration**: Complete GitHub Actions workflow with SARIF output
5. **Vulnerability Prioritization**: Risk-based prioritization engine
6. **Auto-remediation**: Automated fixes for common security issues
7. **Security Dashboard**: Visual metrics and trend analysis
8. **SARIF Output**: Standard format for security dashboard integration

The command follows the established Python command pattern and integrates seamlessly with uv for dependency management.
